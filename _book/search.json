[
  {
    "objectID": "xl-filter-sort.html",
    "href": "xl-filter-sort.html",
    "title": "4  Sorting and filtering to find stories",
    "section": "",
    "text": "After police in Ferguson, Mo., killed Michael Brown in 2014, advocates and journalists began examining the racial and ethnic gaps between police departments and the communities they served.\nThe New York Times found a 7-year-old survey conducted by the Justice Department that allowed it to compare the data for major cities in a standalone graphic that it published later that year.\nWhen newer data reflecting departments’ makeup in 2012 was released a year later, Matt Apuzzo and Sarah Cohen hoped it would show some differences. It didn’t. So we were left trying to find news in the data that was clearly of public interest.\nAfter matching up the demographics of police departments with their cities, I started sorting, filtering and Googling. Could there be news in the outliers on the list? Which departments most closely represented their communities? Which ones had unusually large gaps?\n\n\n\n\nChief William T. Riley III. Credit: Laura McDermott for The New York Times\n\n\n\nI quickly stumbled on telling anecdote to frame the story: Inkster, Mich. had one of the least representative departments in the country, and had recently hired a new police chief to help mend the department’s fraught relationship with its largely African-American community. Where had he come from? Selma, Ala., one of the most representative police departments in the nation. Interviews with the chief, William T. Riley III, suggested one reason for some cities’ disparities: there was no state or federal money to pay for training new police officers.\nThe story, “Police Chiefs, Looking to Diversity Forces, Face Structural Hurdles” helped explain the persistent gap between the makeup of police in some areas and the communities they served."
  },
  {
    "objectID": "xl-filter-sort.html#sorting-and-filtering-as-a-reporting-tool",
    "href": "xl-filter-sort.html#sorting-and-filtering-as-a-reporting-tool",
    "title": "4  Sorting and filtering to find stories",
    "section": "4.2 Sorting and filtering as a reporting tool",
    "text": "4.2 Sorting and filtering as a reporting tool\nSorting and filtering can:\n\nNarrow your focus to specific items that you want to examine in your story.\nShow you rows containing the highest and lowest values of any column. That can be news or it can be errors or other problems with the data.\nLet you answer quick “how many?” questions, with a count of the rows that match your criteria. (In the next lesson, you’ll see that pivot tables, or group-by queries, are much more powerful for this in most cases.)"
  },
  {
    "objectID": "xl-filter-sort.html#example-data",
    "href": "xl-filter-sort.html#example-data",
    "title": "4  Sorting and filtering to find stories",
    "section": "4.3 Example data",
    "text": "4.3 Example data\n::: {.alert .alert-info } - Data from the Washington Post for use in this tutorial - Documentation from the Post’s github site :::\n                                            The data for this and several other chapters is the Washington Post's public data collection of police shootings in the U.S. It includes the nation's best guess about each fatal police shooting since 2015. There are a couple of caveats: \n                                            \n                                            - It excludes deadly police interactions other than shooting a firarem at the suspect. Any strangulation, car crashes, Tasers without guns or other methods  are excluded. \n                                          \n                                          - It is based primarily on news reports and the results public records requests so it often contains the story as told by police. We know that many of those reports are sugar-coated at best, and lies at worst. \n                                          \n                                          - The Post says this is a list of fatal shootings, but doesn't say what happens if more than one person is killed. The [2019 shooting of D'Angelo Brown & Megan Rivera in West Memphis](https://www.wbtv.com/2019/03/15/dash-cam-footage-aided-investigation-into-deadly-police-shooting-no-charges-officers/)  is shown as two rows^[Finding these is something that's pretty hard in a spreadsheet but will be really easy in R.] in the data  even though it was one event. So each row  might  be considered a shooting \"victim\",  a \"suspect\" or a shooting \"fatality\" rather than a \"shooting\". \nThe original data download link is https://github.com/washingtonpost/data-police-shootings/releases/download/v0.1/fatal-police-shootings-data.csv. The screenshots in this tutorial may not match exactly to what you get on their data – It had included incomplete 2021 data, and I added a column for the year.\nIt’s a good example set for us because it’s been used as the basis of many stories, it has at least one of each data type that we plan to deal with in Excel, and it is well documented on the Post’s github site.\n                                                                                                                                                                                                                   ## Understanding data types\n                                                                                                                                                                                                                   \n                                                                                                                                                                                                                   When you open the spreadsheet, the first thing to notice  is its [*granularity*](start-data-def.html). Unlike Census or budget spreadsheets, this is a list capturing specific characteristics of each fatality Each column has the same *type* of data from top to bottom. Those types are: \n                                                                                                                                                                                                                     \n                                                                                                                                                                                                                     - **Text**. Text or \"character\" columns can come in long or short form. When they are standardized (the values can contain only one of a small list of values), they're called \"categorical\". If they're more free-form, they're might be called \"free text\". The computer doesn't know the difference, but you should. The Post data has examples of both. In spreadsheets, text is left-justified (they move toward the left of the cell and will line up vertically at the beginning)\n                                                                                                                                                                                                                   \n                                                                                                                                                                                                                   - **Numbers**. These are pure numbers with no commas, dollar signs or other embellishments. In Excel, as we'll see in the computing section, these can be formatted to *look* like numbers we care about , but underneath they're just numbers. Adding up a column of numbers that has a word in it or has missing values will just be ignored in Excel. It will trip up most other languages.  These are right-justified, so the last digit is always lined up vertically. \n                                                                                                                                                                                                                   \n                                                                                                                                                                                                                   - **Logical**: This is a subset of text. It can take one of only two values -- yes or no, true or false. There is no \"maybe\". \n                                                                                                                                                                                                                   \n                                                                                                                                                                                                                   - **Date and times**: These are actual dates on the calendar, which have magical properties. Underneath, they are a number. In Excel, that number is the number of days since Jan. 1, 1900.^[Each language deals with dates and times  a little differently. We'll see how R does it later on. But just know that dates can be tricky because of these differences and [time is even more tricky](https://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time) ] They can also have time attached to them, which in Excel is a fraction of a day. What this means is that the number 44,536.5  is really Dec. 6, 2021 at noon. In Excel, you use a format to tell the spreadsheet how you want to see the date or time, just the way you look at dollar values with commas and symbols. (If you get a spreadsheet with a lot of dates of 1/1/1900, it means there is a 0 in that column, which is sometimes a fill-in for \"I don't know.\")\nHere’s a picture of a date that is shown in a variety of formats.\n\n\n\ndate formats\n\n\nAll of these are the same, underlying value – the number at the left. Notice that all of these are right-justified.\nThis means that when you see “Friday, December 10”, the computer sees 44540.87431. When you put the dates in order, they won’t be alphabetized with all of the Fridays shown together. Instead, they’ll be arranged by the actual date and time.\nIt also means that you can compute 911 response times even when it crosses midnight, or or compute the someone’s age today given a date of birth. Keeping actual calendar dates in your data will give it much more power than just having the words. (Excel uses the 1st of the month as a stand-in for an actual date when all you know is the month and year.)"
  },
  {
    "objectID": "xl-filter-sort.html#working-with-excel-tables",
    "href": "xl-filter-sort.html#working-with-excel-tables",
    "title": "4  Sorting and filtering to find stories",
    "section": "4.4 Working with Excel “tables”",
    "text": "4.4 Working with Excel “tables”\nExcel lets you put any type of data anywhere on your spreadsheet. To bring a little order to the chaos, it allows you to turn your data into a “table”, which is set up for sorting and filtering. It enforces some data types on you, and deals with missing information more smoothly. It is designed for tabular data without empty rows or columns, and where there is nothing else on the sheet.\nPut your cursor somewhere in the table, then use the “Format as table” button on the home screen. Check to make sure the “My table has headers” is checked.\n\n\n4.4.1 Sorting rows\nSorting means rearranging the rows of a data table into a different order. Some reporters take a conceptual shortcut and call this “sorting columns”. That thinking will only get you into trouble – it lets you forget that you want to keep the rows in tact while changing the order in which you see them. In fact, in other languages it’s called “order by” or “arrange” by one or more columns – a much clearer way to think of it.\nIn Excel, look for the sort options under the Data tab at the top of your screen. In this case, sorting from oldest to newest gives you a list of the fatalities in chronological order, including the time of day.\nTo sort your data, put your cursor in one of the cells within your data area, and choose Data…Sort. Please don’t use the A->Z or Z->A buttons!\n\n\nAdding fields to the sort\nAdding more columns to the sort box tells Excel what to do when the first one is the same or tied. For example, sorting first by state then by date gives you a list that shows all of the events by state in sequence:\n\n\n\n\n4.4.2 Filtering\nFiltering means picking out only some of the rows you want to see based on a criteria you select in a column. Think of it as casting a fishing net – the more filters you add, the fewer fish will be caught.\nWhen you created the table, it also created little drop-down arrows on the top row. If you can’t see them, use CTL-HOME or CTL-UP on the first column to get yourself back to the top. Each filter you select adds more conditions, narrowing your net.\nTo find fatalities that involved a firearm with a Taser, use the drop-down menu under manner_of_death select it. (This is an example of naming a column in an unexpected way. Usually, a “manner” of death relates to the circumstances such as accident, suicide or homicide. It’s why you can’t count on understanding the column names without a crib sheet from the data’s maker, called a data dictionary or record layout. The Post’s crib sheet is excellent!)\nWhen you do this, notice that the bottom left briefly shows you the number of rows that matched your filter, and the line numbers turn blue. Any rows that don’t match your filter hidden.\n\n\nThis method works for small-ish and simple-ish columns. If your column has more than 10,000 different entries, such as names or addresses, only the first 10,000 will be considered. We only caught these for stories when someone did a fact-check using a different method of filtering. If your column has a lot of distinct entries, use option that says “Choose One”, and then use the “Contains” option. Better yet, don’t use filtering for counting things at all.\n\nAdd more filters to narrow down your list of cases even more. For example, the New York Times ran a series of stories in 2021 about unarmed people shot by police. One story was about those who were fleeing by car. Here’s one way to get a preliminary list of those cases:\n\nRemove any filter you already have on.\nTurn on the filters again if you turned them off.\nChoose “unarmed” under armed and “car” under flee.\n\n(Of course, the Times didn’t stop there in trying to find more cases and teasing out more of them from this and other data. But this is a start. )\n\n\nDifferent kinds of filters\nThere are several options under the filter box, depending on what data type in in the column. In numeric columns, you can get top and bottom lists. Dates will automatically collapse into years, then months, then days to let you choose more efficiently."
  },
  {
    "objectID": "xl-filter-sort.html#video-of-sorting-and-filtering-with-salaries",
    "href": "xl-filter-sort.html#video-of-sorting-and-filtering-with-salaries",
    "title": "4  Sorting and filtering to find stories",
    "section": "4.5 Video of sorting and filtering with salaries",
    "text": "4.5 Video of sorting and filtering with salaries\nThis video goes through many of the details of sorting and filtering. Follow along using this spreadsheet of Phoenix city salaries. It’s from a different year, but the idea is just the same.\nNote that in this case, the original order of the dataset was alphabetical, except lower-case names came at the very end. It would be very hard to get back to this order in a spreadsheet if you didn’t have that leftmost column of numbers that indicated the original order."
  },
  {
    "objectID": "xl-filter-sort.html#faq",
    "href": "xl-filter-sort.html#faq",
    "title": "4  Sorting and filtering to find stories",
    "section": "4.6 FAQ",
    "text": "4.6 FAQ\n\nHow do I turn off all of my sort and filters\nIn the data tab, chose “Clear” (the funnel with the red “X”) to remove all of the filters and sorts on your table.\n\n\nWhere is the button to filter columns?\nSometimes you don’t want to see all of your columns – there are too many and they’re getting confusing. There is no column filter in Excel. (You’ll see how to filter, or “Select”, columns from a dataset in standard programming languages later.)\nInstead, you can hide the columns you don’t want to see. When columns and rows are hidden, they generally won’t copy to a new sheet.\n\n\nI’m getting weird questions and alerts about sorting\nSlow down and read the alert. There are two common types of alerts in sorting, since it has the potential to wreck your spreadsheet.\nThe first comes if you selected an entire column, and then just hit the button that says “A-Z” with the arrow. Excel won’t let you do that if it’s formatted as a table, but it will if it’s just a normal spreadsheet. This alert asks you if you REALLY want to sort only the column you’ve selected, separating its meaning from the rest of the rows. The answer is NO. Always. Expand the selection as Excel wants you do to by default.\n\n\n\nfilter date\n\n\nThe other comes when you have numbers that are treated as text. This is a tricky question, and a properly tidied spreadsheet should avoid it most of the time. If you have the same type of data in each column, the answer to this question shouldn’t matter. If not, neither one will give you what you want.\n\n\nI want to get rid of my data table\nYou can revert to the a plain old spreadsheet by selecting any cell within your table, then looking for the “Table” tab at the top of your screen. Choose the option that says “Convert to Range”."
  },
  {
    "objectID": "geographicanalysis.html",
    "href": "geographicanalysis.html",
    "title": "28  Geographic analysis",
    "section": "",
    "text": "First, let’s load the libraries we’ll need. We’re also going to load tidycensus and set an API key for tidycensus.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(tidycensus)\ncensus_api_key(\"549950d36c22ff16455fe196bbbd01d63cfbe6cf\")\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\n\nAnd now let’s load a dataframe of Maryland county population information from the 2020 Census, but this time we’ll add in county geographic data.\n\nmaryland_counties <- read_csv(\"data/md_counties_2020.csv\")\n\nRows: 24 Columns: 39\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): SUMLEV, GEOCODE, NAME, BASENAME, FILEID, STUSAB, CHARITER, CIFSN\ndbl (31): GEOID, LOGRECNO, TOTAL_POP, POP_ONE_RACE, POP_WHITE, POP_BLACK, PO...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmaryland_county_shapes <- st_read(\"data/Maryland2020_County.json\")\n\nReading layer `Maryland2020_County' from data source \n  `/Users/dpwillis/code/datajournalismbook-elections/data/Maryland2020_County.json' \n  using driver `ESRIJSON'\nSimple feature collection with 24 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -79.48765 ymin: 37.8866 xmax: -74.98628 ymax: 39.72304\nGeodetic CRS:  NAD83\n\nmaryland_counties_with_shapes <- maryland_counties %>% inner_join(maryland_county_shapes, by=c('GEOID'='GEOID20'))\n\nError in `inner_join()`:\n! Can't join on `x$GEOID` x `y$GEOID` because of incompatible types.\nℹ `x$GEOID` is of type <double>>.\nℹ `y$GEOID` is of type <character>>.\n\n\nAnd there’s that join error: we’ve got incompatible data types. We can quickly fix that:\n\nmaryland_counties <- read_csv(\"data/md_counties_2020.csv\") %>% mutate(GEOID = as.character(GEOID))\n\nRows: 24 Columns: 39\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): SUMLEV, GEOCODE, NAME, BASENAME, FILEID, STUSAB, CHARITER, CIFSN\ndbl (31): GEOID, LOGRECNO, TOTAL_POP, POP_ONE_RACE, POP_WHITE, POP_BLACK, PO...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmaryland_county_shapes <- st_read(\"data/Maryland2020_County.json\")\n\nReading layer `Maryland2020_County' from data source \n  `/Users/dpwillis/code/datajournalismbook-elections/data/Maryland2020_County.json' \n  using driver `ESRIJSON'\nSimple feature collection with 24 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -79.48765 ymin: 37.8866 xmax: -74.98628 ymax: 39.72304\nGeodetic CRS:  NAD83\n\nmaryland_counties_with_shapes <- maryland_counties %>% inner_join(maryland_county_shapes, by=c('GEOID'='GEOID20'))\n\nFor the rest of this chapter, we’re going to work on building a map that will help us gain insight into geographic patterns in registered voters and population by county and in Maryland. Our starting question: by examining the number of voters and the population in each county, what regional geographic patterns can we identify?\nFirst we need to load voter registration data - since the population data is from 2020, we’ll use the county totals as of the 2020 general election. And we’ll make sure that the FIPS code that we need to join on is a character column:\n\nmaryland_voters_by_county <- read_csv(\"data/maryland_voters_2020g.csv\") %>% mutate(FIPS=as.character(FIPS))\n\nRows: 24 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): County\ndbl (10): FIPS, DEM, REP, BAR, GRN, LIB, WCP, OTH, UNA, TOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNow let’s combine our two dataframes:\n\nmaryland_voters_by_county_with_pop <- maryland_voters_by_county %>% inner_join(maryland_counties_with_shapes, by=c('FIPS'='GEOID'))\n\nNow we can do some calculations and visualize them on a map. Let’s calculate the number of Unaffiliated (no party) voters per 10,000 people and take a look at just the numbers.\n\nmd_una_per_10k <- maryland_voters_by_county_with_pop %>%\n  mutate(una_per_10k = UNA/TOTAL_POP*10000) %>%\n  arrange(desc(una_per_10k)) %>% \n  select(County, DEM, REP, OTH, UNA, TOTAL, una_per_10k, geometry)\n\nmd_una_per_10k\n\n# A tibble: 24 × 8\n   County          DEM    REP   OTH    UNA  TOTAL una_per_10k\n   <chr>         <dbl>  <dbl> <dbl>  <dbl>  <dbl>       <dbl>\n 1 Frederick     72487  68767   801  42961 186356       2069.\n 2 Howard       118705  52748  2035  51909 226634       2067.\n 3 Calvert       24587  28181   567  14178  67984       1999.\n 4 Anne Arundel 174494 135457  2715  90162 405616       1977.\n 5 Carroll       33662  63967  1072  25770 125361       1908.\n 6 Cecil         21601  30880   727  15110  68819       1878.\n 7 Harford       66258  80038  1535  37942 187092       1875.\n 8 Queen Anne's  11091  18930   280   7133  37678       1824.\n 9 Saint Mary's  26373  30661   606  15661  73833       1813.\n10 Montgomery   410935 105561  5816 147417 673198       1800.\n# … with 14 more rows, and 1 more variable: geometry <POLYGON [°]>\n\n\nLet’s take a look at the result of this table. We might call this where the swing voters are, although political science tells us that most independents actually vote with a party most of the time. Frederick, Howard, Calvert, Anne Arundel and Carroll counties all have some competitive races at the local and state level, so that makes some sense. Montgomery, the state’s largest jurisdiction, has more independents than Republicans.\nOkay, now let’s visualize. We’re going to build a choropleth map, with the color of each county – the fill – set according to the number of unaffiliated voters per 10K on a color gradient.\n\nggplot() +\n  geom_sf(data=md_una_per_10k, aes(fill=una_per_10k)) +\n  theme_minimal()\n\nError in `check_required_aesthetics()`:\n! stat_sf requires the following missing aesthetics: geometry\n\n\n\n\n\nSo this error message is pretty sneaky, because it’s saying that it can’t find a geometry column. But we have a geometry column - it’s called geometry! What’s happening here is that ggplot expects certain details in order to be able to locate the column with geometry in it, and sometimes when we build a new dataframe through joins those details get dropped. Luckily, we can explicitly tell ggplot where to find it:\n\nggplot() +\n  geom_sf(data=md_una_per_10k, aes(fill=una_per_10k, geometry=geometry)) +\n  theme_minimal()\n\n\n\n\nThis map is okay, but the color scale makes it hard to draw fine-grained differences. Let’s try applying the magma color scale we learned in the last chapter.\n\nggplot() +\n  geom_sf(data=md_una_per_10k, aes(fill=una_per_10k, geometry=geometry)) +\n  theme_minimal() +\n  scale_fill_viridis_b(option=\"magma\")\n\n\n\n\nSome interesting regional patterns finally emerge.\nThe highest number of unaffiliated voters per capita are clustered close to DC and Baltimore, with the notable exception of Prince George’s County. The further west you go, the lower number of unaffiliated voters per capita there are (and that’s somewhat true for the Eastern Shore, too). You could swap out UNA for Republicans or Democrats, or look at this another way, but what you’re trying to see here are potential patterns for further exploration."
  }
]