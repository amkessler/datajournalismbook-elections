---
title: "lab_06"
author: "derek willis"
date: "8/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

* Tabula

## Load libraries and establish settings
```{r}
# Turn off scientific notation
options(scipen=999)

# Load the tidyverse.
library(tidyverse)
library(janitor)
```

## Get Our PDF

We'll be working with the [Maryland monthly voter registration update](https://elections.maryland.gov/pdf/vrar/2022_09.pdf) from the State Board of Elections. You'll want to download it to a place you'll remember (like your Downloads folder, or the labs folder in your repository). The goal is to write a couple of paragraphs that summarize the changes in voter registration in Maryland during the month of September.

## Setup Tabula

Start Tabula, then go to http://127.0.0.1:8080/ in your browser. Click the "Browse" button and find the PDF file and click "open", and then click the "Import button" in Tabula. This will take a few seconds.

This PDF has multiple possible tables to extract. We're going to make four dataframes: new registrations by party, removals by party, changes in registration and current registrations by county. You will need to draw boxes around four sections and export four CSV files that you will load into R. In Tabula, draw a box around the borders of those tables and click the "Preview & Export Extracted Data" button for each one. The export should look pretty clean.

Export each CSV (each one should be called `tabula-2022-09.csv` by default, so you should rename them for clarity) to your lab_06/data folder.

From there, you will need to read in and clean up the data, and in particular the headers. You can choose to include the headers from the PDF in your exported CSV files OR to exclude them and add them when importing. `read_csv` allows us to do this ([and more](https://readr.tidyverse.org/reference/read_delim.html)).

## Load and clean up the data in R

You will need to read in and clean up the data so that it can be used for analysis. By "clean" I mean the column headers should not contain spaces and should have meaningful names, not "x1" or something similar. For all four files you should add columns representing the month (9) and year (2022) and populate them. The current registrations dataframe *MUST* include the county name, but should not include the columns under `Changes` and `Party Affiliation From`. How you do that is up to you (and could involve something outside R), but you can use select() with or without the minus sign to include or exclude certain columns. 

```{r}
# Party registrations
new_registrations_sep22 <- read_csv("data/party_registrations.csv") %>% clean_names()

new_registrations_sep22 <- new_registrations_sep22 %>% 
  rename(category = x1) %>% 
  mutate(year = 2022, month = 9)
```

```{r}
# Removals
removals_sep22 <- read_csv("data/removals.csv") %>% clean_names()

removals_sep22 <- removals_sep22 %>% 
  rename(category = x1) %>% 
  mutate(year = 2022, month = 9)
```

```{r}
# Changes
changes_sep22 <- read_csv("data/changes.csv") %>% clean_names()

changes_sep22 <- changes_sep22 %>% 
  rename(county = x1) %>% 
  mutate(year = 2022, month = 9)

```

```{r}
# Current registrations
current_sep22 <- read_csv("data/current.csv") %>%
  select(-c(2,3,4,5,6,7,8,9,10,11)) %>% 
  clean_names()

current_sep22 <- current_sep22 %>% 
  rename(county = x1) %>% 
  rename(dem = dem_12, rep = rep_13, grn = grn_14, lib = lib_15, wcp = wcp_16, unaf = unaf_17, oth = oth_18, total = total_19) %>%
  mutate(year = 2022, month = 9)
```

## Answer questions

Q1. Which region and county/city below the state level accounted for the largest percentage of international migration overall?  You'll need to add and populate columns representing percent of total using `mutate`.
A1. Suburban Washington (62.8%). Montgomery County (36.8%).

```{r}
international_migration %>%
  mutate(pct_total=(total/198996)*100) %>%
  select(jurisdiction, pct_total) %>%
  arrange(desc(pct_total))
```

Q2. Write a sentence or two that describes the data you produced in A1. Treat this as if you were trying to convey the most important part.
A2. International migrants to Maryland during the past 10 years were drawn mostly to the suburbs surrounding Washington, D.C., which accounted for more than six of every 10 foreign residents that moved to the state between July 2010 and July 2019.

Q3. Which region & jurisdiction had the biggest percentage change for international migration between July 2018 and July 2017? The formula for percentage change is easy to remember: (New-Old)/Old.
A3. Calvert County's international migrants declined 76 percent (albeit from a small population), and the Southern Maryland region declined 58.5 percent.

```{r}
international_migration %>%
  mutate(pct_change=((july_2018-july_2017)/july_2017)*100) %>%
  select(jurisdiction, pct_change) %>%
  arrange(pct_change)
```

Q4. What's your best guess as to why these declines occurred, and in those area in particular?
A4. One answer is that with the advent of the Trump administration, controls on international migration tightened.

## Back to Tabula

Let's go to page 31 of the PDF, Table 2B, "Domestic Migration for Maryland's Jurisdictions, July 1, 2010 to July 1, 2019". In Tabula, hit the "Clear All Selections" button and then draw a box around that table's border and click the "Preview & Export Extracted Data" button. It should look pretty clean. Let's export that CSV to your Downloads folder (let's rename it to `tabula-md-statistical-handbook-domestic.csv`).

## Cleaning up the data in R

Let's load it into R, and in doing so we'll skip the first two rows and add our own headers that are cleaner:

```{r}
domestic_migration <- read_csv('tabula-md-statistical-handbook-domestic.csv', skip=2, col_names=c("jurisdiction", "july_2011", "july_2012", "july_2013", "july_2014", "july_2015", "july_2016", "july_2017", "july_2018", "july_2019", "total"))
```

Add a column for the type of migration ("domestic") and populate it:

```{r}
domestic_migration <- domestic_migration %>% mutate(type='domestic')
```

## Answer questions
Q5. Which Maryland individual jurisdiction saw the largest net decrease in domestic migration overall?
A5. Baltimore City, with -62,834, with Prince George's County not far behind at -60,167.

```{r}
domestic_migration %>%
  select(jurisdiction, total) %>%
  arrange(total)
```

Q6. How many regions & jurisdictions had net positive migration for July 2017, July 2018 and July 2019?
A6. 14, including the Southern Maryland and Upper Eastern Shore regions.

```{r}
domestic_migration %>%
  filter(july_2017 > 0 & july_2018 > 0 & july_2019 > 0) %>%
  select(jurisdiction, july_2017, july_2018, july_2019)
```

Q7. How would you describe this data? Is there a county or region that stands out, and why?
A7. Frederick and Charles stand out for consistent growth, and Caroline for trending downwards.
